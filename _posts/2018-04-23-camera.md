---
layout: post
comments: true
title: Comparativo de sensores - Nikon d7000 vs Galaxy S7
---

Há muito que se presencia no mercado uma sorrateira substituição das
câmeras reflex pelas câmeras dos telefones celulares, cada vez
melhores a cada ano. De fato, para a maioria dos usuários, pouca
diferença faz se a foto é tirada usando uma câmera reflex, fruto de um
investimento adicional, ou com um telefone. Afinal, as resoluções das
fotos são praticamentes as mesmas, correto?! Não é bem assim, e um
experimento bem simples pode mostrar coisas que normalmente ficam
escondidas de olhos menos atentos. Pelo menos foi o que observei com
um experimento feito usando um Galaxy S7 e uma Nikon d7000.

<!--break-->

Todas as câmeras possuem um sensor de área. É uma peça retangular que
fica dentro do aparelho (pasmem!) e recebe a luz da cena que se deseja
fotografar e a transforma em uma matriz de pontos coloridos. Todo
sensor possui uma resolução, normalmente associado com a quantidade de
pontos dessa matriz.

Via de regra, quanto maior a resolução, maior a quantidade de detalhes
que é possível capturar numa cena. Sim, de fato, isso ocorre. Porém,
mais detalhes não significa necessariamente mais qualidade. E isso
advém da própria física dos materiais que compõem o sensor.

Os sensores de área funcionam mais ou menos como formas de gelo
expostas à chuva. Se os buracos da forma são grandes, ao final de uma
chuva, cada buraco parecerá cheio aproximadamente com a mesma
quantidade de água. Se os buracos são pequenos, alguns ficarão mais
cheios que outros. Assim também funcionam com os sensores de
luz. Quanto maior o tamanho das células do sensor, mais "pingos da
chuva de fótons" serão capturados por cada uma delas.

A figura abaixo ilustra a proporção entre os tamanhos dos sensores de
uma Nikon D7000 e de um Galaxy S7. Embora consigam tirar fotos em
resoluções parecidas, o sensor da D7000 é bem maior.

[![]({{ site.url }}/images/sensor/tamanhosensor.svg)]({{ site.url }}/images/sensor/tamanhosensor.svg)

E o que ocorre quando o sensor é pequeno demais? Ruído. Sim, ruído. A
pouca exposição à luz excita de forma desordenada os elementos do
sensor (mais que nos sensores de grande área) provocando variações de
cor.

Se os elementos do sensor possuem área reduzida, é natural que regiões
suaves de uma cena apresentem ligeiras variações de cor que,
normalmente, são imperceptíveis quando se captura a imagem em um
telefone. Entretanto, ao se levar a imagem para um Desktop ou imprimir
a foto capturada, a qualidade não é a mesma que se obtém com uma
fotografia tirada com uma câmera profissional.

## Medindo o ruído em uma câmera

Resolvi estimar o ruído que uma câmera produz através de um
experimento bem simples: removendo todas as fontes de luz de modo que
somente a própria câmera influenciasse no processo de geração da cena.

Em linhas gerais, uma imagem pode ser representada como a composição
de três quantidades \\[ImagemCapturada = ImagemPura + Polarizacao + Ruido \\]

A polarização é a suposta imagem que restaria se não houvesse ruído e
a câmera estivesse na ausência total de luz; a imagem pura é aquela
que seria gerada com um sensor perfeito (sem polarização e sem ruído);
e o ruído seria o lixo gerado na ausência de luz e com baixa
polarização.

Então, para criar uma situação onde o ruído fosse posto em evidência
criei uma estratégia bem simples. Obstruí o sensor da câmera e tirei a
fotografia. No Galaxy S7, tapei a lente usando duas camadas de fita
isolante. Na Nikon D7000, basta colocar o protetor da lente que toda
a luz é obstruída.

Ambas as câmeras foram ajustadas no modo automático e duas fotos foram
tiradas. 
O Galaxy S7 produziu a seguinte imagem:
[![Foto tomada com o Galaxy S7]({{ site.url }}/images/sensor/galaxys7.jpg)]({{ site.url }}/images/sensor/galaxys7.jpg)

A Nikon D7000 produziu a seguinte imagem:
[![Foto tomadao com a Nikon D7000]({{ site.url }}/images/sensor/nikond7000.jpg)]({{ site.url }}/images/sensor/nikond7000.jpg)


A princípio, as imagens parecem idênticas, pois o olho humano tem
péssimo comportamento para analizar o contraste com tons
parecidos. Mas carregando as fotos no computador e obtendo os
histogramas das imagens geradas por cada dispositivo informações
importantes aparecem (Em tempo, os histogramas mede a quantidade de
ocorrências de cada tom de cor para todos os pixels da imagem).

Para o Galaxy S7, obtivemos os seguintes histogramas para as
componentes vermelho, verde e azul da imagem capturada.

[![Sensor Galaxy S7]({{ site.url }}/images/sensor/histogalaxy.svg)]({{ site.url }}/images/sensor/histogalaxy.svg)

Para a Nikon D7000, obtivemos os seguintes histogramas para as
componentes vermelho, verde e azul da imagem capturada.

[![Sensor Nikon D7000]({{ site.url }}/images/sensor/histonikond7000.svg)]({{ site.url }}/images/sensor/histonikond7000.svg)

A imagem do Galaxy S7 está recheada de ruído. O que deveria idealmente
ser uma imagem completamente preta, produzindo um histograma com
apenas um pico na cor "0", temos pixels que se espalham dos tons na
faixa aproximada dos 10 a 25 para a totalidade da imagem.

A imagem da Nikon D7000, por sua vez, praticamente não apresenta
ruído. A quase totalidade dos pixels possuem tons de cor próximos ao
"0", valor considerado ideal. O gráfico desenhado, inclusive, é
mostrado em escala vertical logarítimica para dar uma ideia melhor da
relação entre a quantidade de ocorrência de pontos com cor "preta" e
pontos com outras cores também bem próximas ao preta. Em outras
palavras, as imagens tomadas com câmeras reflex com sensor de grande área
são mais limpas que imagens tomadas com telefones.

E onde é que o olho normalmente é enganado? É que quando você vê a
foto no dispositivo, ele aparece em tamanho reduzido. E, para
completar, o tamanho dos pixels de um telefone é ínfimos, de sorte que
é praticamente impossível conseguir distinguir entre dois pixels
vizinhos.

Olha o que acontece quando a imagem do ruído quando ela sofre uma
redução de tamanho para uma altura de 1080 linhas: o ruído diminui. O
processo de interpolação usado na redução das imagens atenua o ruído,
melhorando ainda mais a experiência de ver no telefone. Mas, a imagem
que se vê não é a mesma que poderá ser impressa.

[![Sensor Nikon D7000]({{ site.url }}/images/sensor/compar-reduzida.svg)]({{ site.url }}/images/sensor/compar-reduzida.svg)

Capturei um pequeno vídeo com o Galaxy S7 e calculei a média dos
quadros para estimar a polarização da cena. Para o Galaxy, os pixels
apresentam valores bem baixos próximos dos 3 ou 4 tons que, para fins
de análise, podem ser considerados insignificantes. A Nikon D7000
produziu uma imagem totalmente nula, mostrando a qualidade da marca.

Em suma, embora bem rudimentar, o experimento sugere que a tecnologia
das câmeras usadas em telefones celulares não consegue superar a
qualidade de uma câmera com maior sensor de área.

É bem provável que em mais alguns anos as câmera reflex entrem em
desuso (profissional), mas até lá ainda teremos que evoluir bastante.